!
! auto-generated by ops_fortran.py
!
MODULE UPDATE_KERNEL_MODULE
USE OPS_FORTRAN_DECLARATIONS
USE OPS_FORTRAN_RT_SUPPORT

USE OPS_CONSTANTS
USE ISO_C_BINDING
USE CUDAFOR

INTEGER(KIND=4), constant :: xdim1_update_kernel
INTEGER(KIND=4):: xdim1_update_kernel_h  = -1
#define OPS_ACC1(x) (x+1)
INTEGER(KIND=4), constant :: xdim2_update_kernel
INTEGER(KIND=4):: xdim2_update_kernel_h  = -1
#define OPS_ACC2(x) (x+1)
INTEGER(KIND=4), constant :: xdim3_update_kernel
INTEGER(KIND=4):: xdim3_update_kernel_h  = -1
#define OPS_ACC3(x) (x+1)

INTEGER(KIND=4), constant :: xdim4_update_kernel
INTEGER(KIND=4):: xdim4_update_kernel_h  = -1
#define OPS_ACC_MD4(d,x) ((x)*3+(d))

contains

!user function
attributes (device) subroutine update_kernel_gpu(rho_new, rhou_new, rhoE_new, s)

  real (kind=8), DIMENSION(1) :: rho_new, rhou_new, rhoE_new
  real (kind=8), INTENT(in), DIMENSION(3) :: s

  rho_new(OPS_ACC1(0))  = rho_new(OPS_ACC1(0))  + s(OPS_ACC_MD4(1,0));
  rhou_new(OPS_ACC2(0)) = rhou_new(OPS_ACC2(0)) + s(OPS_ACC_MD4(2,0));
  rhoE_new(OPS_ACC3(0)) = rhoE_new(OPS_ACC3(0)) + s(OPS_ACC_MD4(3,0));

end subroutine


#undef OPS_ACC1
#undef OPS_ACC2
#undef OPS_ACC3

#undef OPS_ACC_MD4


!CUDA kernel function -- wrapper calling user kernel
attributes (global) subroutine update_kernel_wrap( &
& opsDat1Local, &
& opsDat2Local, &
& opsDat3Local, &
& opsDat4Local, &
& dat1_base, &
& dat2_base, &
& dat3_base, &
& dat4_base, &
& size1 )
  IMPLICIT NONE
  real(8), DEVICE :: opsDat1Local(*)
  integer(4) arg1
  real(8), DEVICE :: opsDat2Local(*)
  integer(4) arg2
  real(8), DEVICE :: opsDat3Local(*)
  integer(4) arg3
  real(8), DEVICE, INTENT(IN) :: opsDat4Local(*)
  integer(4) arg4
  integer(4), value :: dat1_base
  integer(4), value :: dat2_base
  integer(4), value :: dat3_base
  integer(4), value :: dat4_base
  integer(4) start(1)
  integer(4) end(1)
  integer, value :: size1
  integer n_x


  n_x = blockDim%x * (blockIdx%x-1) + threadIdx%x

  arg1 = (n_x-1) * 1*1
  arg2 = (n_x-1) * 1*1
  arg3 = (n_x-1) * 1*1
  arg4 = (n_x-1) * 1*3
  IF ((n_x-1) < size1) THEN
    call update_kernel_gpu( &
    & opsDat1Local(dat1_base+arg1), &
    & opsDat2Local(dat2_base+arg2), &
    & opsDat3Local(dat3_base+arg3), &
    & opsDat4Local(dat4_base+arg4) )

  ENDIF


end subroutine

!host subroutine
attributes (host) subroutine update_kernel_host( userSubroutine, block, dim, range, &
& opsArg1, &
& opsArg2, &
& opsArg3, &
& opsArg4)
  use cudafor
  IMPLICIT NONE
  character(kind=c_char,len=*), INTENT(IN) :: userSubroutine
  type ( ops_block ), INTENT(IN) :: block
  integer(kind=4), INTENT(IN):: dim
  integer(kind=4)   , DIMENSION(dim), INTENT(IN) :: range
  real(kind=8) t1,t2,t3
  real(kind=4) transfer_total, transfer
  integer(kind=4) :: istat

  type ( ops_arg )  , INTENT(IN) :: opsArg1
  real(8), DIMENSION(:), DEVICE, POINTER  :: opsDat1Local
  integer(kind=4) :: opsDat1Cardinality
  integer(kind=4), POINTER, DIMENSION(:)  :: dat1_size
  integer(kind=4) :: dat1_base
  INTEGER(KIND=4) :: xdim1

  type ( ops_arg )  , INTENT(IN) :: opsArg2
  real(8), DIMENSION(:), DEVICE, POINTER  :: opsDat2Local
  integer(kind=4) :: opsDat2Cardinality
  integer(kind=4), POINTER, DIMENSION(:)  :: dat2_size
  integer(kind=4) :: dat2_base
  INTEGER(KIND=4) :: xdim2

  type ( ops_arg )  , INTENT(IN) :: opsArg3
  real(8), DIMENSION(:), DEVICE, POINTER  :: opsDat3Local
  integer(kind=4) :: opsDat3Cardinality
  integer(kind=4), POINTER, DIMENSION(:)  :: dat3_size
  integer(kind=4) :: dat3_base
  INTEGER(KIND=4) :: xdim3

  type ( ops_arg )  , INTENT(IN) :: opsArg4
  real(8), DIMENSION(:), DEVICE, POINTER  :: opsDat4Local
  integer(kind=4) :: opsDat4Cardinality
  integer(kind=4), POINTER, DIMENSION(:)  :: dat4_size
  integer(kind=4) :: dat4_base
  INTEGER(KIND=4) :: xdim4
  INTEGER(KIND=4) :: multi_d4


  integer x_size
  integer start(1)
  integer end(1)
  integer(kind=4) :: n
  integer(kind=4) :: i10
  integer(kind=4) :: i20
  integer(kind=4) :: blocksPerGrid
  integer(kind=4) :: nshared
  integer(kind=4) :: nthread

  !cuda grid and thread block sizes
  type(dim3) :: grid, tblock

  type ( ops_arg ) , DIMENSION(4) :: opsArgArray

  opsArgArray(1) = opsArg1
  opsArgArray(2) = opsArg2
  opsArgArray(3) = opsArg3
  opsArgArray(4) = opsArg4

  call setKernelTime(13,userSubroutine//char(0),0.0_8,0.0_8,0.0_4,0)
  call ops_timers_core(t1)

#ifdef OPS_MPI
  IF (getRange(block, start, end, range) < 0) THEN
    return
  ENDIF
#else
  DO n = 1, 1
    start(n) = range(2*n-1)
    end(n) = range(2*n)
  END DO
#endif


  x_size = MAX(0,end(1)-start(1)+1)

  call c_f_pointer(getDatSizeFromOpsArg(opsArg1),dat1_size,(/dim/))
  xdim1 = dat1_size(1)
  opsDat1Cardinality = opsArg1%dim * xdim1
  dat1_base = getDatBaseFromOpsArg1D(opsArg1,start,1)
  call c_f_pointer(opsArg1%data_d,opsDat1Local,(/opsDat1Cardinality/))

  call c_f_pointer(getDatSizeFromOpsArg(opsArg2),dat2_size,(/dim/))
  xdim2 = dat2_size(1)
  opsDat2Cardinality = opsArg2%dim * xdim2
  dat2_base = getDatBaseFromOpsArg1D(opsArg2,start,1)
  call c_f_pointer(opsArg2%data_d,opsDat2Local,(/opsDat2Cardinality/))

  call c_f_pointer(getDatSizeFromOpsArg(opsArg3),dat3_size,(/dim/))
  xdim3 = dat3_size(1)
  opsDat3Cardinality = opsArg3%dim * xdim3
  dat3_base = getDatBaseFromOpsArg1D(opsArg3,start,1)
  call c_f_pointer(opsArg3%data_d,opsDat3Local,(/opsDat3Cardinality/))

  call c_f_pointer(getDatSizeFromOpsArg(opsArg4),dat4_size,(/dim/))
  xdim4 = dat4_size(1)
  opsDat4Cardinality = opsArg4%dim * xdim4
  multi_d4 = getDatDimFromOpsArg(opsArg4) ! dimension of the dat
  dat4_base = getDatBaseFromOpsArg1D(opsArg4,start,multi_d4)
  call c_f_pointer(opsArg4%data_d,opsDat4Local,(/opsDat4Cardinality/))

  IF ((xdim1 .NE. xdim1_update_kernel_h) .OR. &
  (xdim2 .NE. xdim2_update_kernel_h) .OR. &
  (xdim3 .NE. xdim3_update_kernel_h) .OR. &
  (xdim4 .NE. xdim4_update_kernel_h) ) THEN
    xdim1_update_kernel = xdim1
    xdim1_update_kernel_h = xdim1
    xdim2_update_kernel = xdim2
    xdim2_update_kernel_h = xdim2
    xdim3_update_kernel = xdim3
    xdim3_update_kernel_h = xdim3
    xdim4_update_kernel = xdim4
    xdim4_update_kernel_h = xdim4
  ENDIF

  grid = dim3( (x_size-1)/getOPS_block_size_x()+ 1, 1, 1)
  tblock = dim3(getOPS_block_size_x(),1,1)


  !halo exchanges
  call ops_H_D_exchanges_device(opsArgArray,4)
  call ops_halo_exchanges(opsArgArray,4,range)
  call ops_H_D_exchanges_device(opsArgArray,4)

  call ops_timers_core(t2)
  call update_kernel_wrap <<<grid,tblock>>> (&
  & opsDat1Local, &
  & opsDat2Local, &
  & opsDat3Local, &
  & opsDat4Local, &
  & dat1_base, &
  & dat2_base, &
  & dat3_base, &
  & dat4_base, &
  & x_size )

  istat = cudaDeviceSynchronize()
  call ops_timers_core(t3)
  call ops_set_dirtybit_device(opsArgArray, 4)
  call ops_set_halo_dirtybit3(opsArg1,range)
  call ops_set_halo_dirtybit3(opsArg2,range)
  call ops_set_halo_dirtybit3(opsArg3,range)

  !Timing and data movement
  transfer_total = 0.0_4
  call ops_compute_transfer(1, start, end, opsArg1,transfer)
  transfer_total = transfer_total + transfer
  call ops_compute_transfer(1, start, end, opsArg2,transfer)
  transfer_total = transfer_total + transfer
  call ops_compute_transfer(1, start, end, opsArg3,transfer)
  transfer_total = transfer_total + transfer
  call ops_compute_transfer(1, start, end, opsArg4,transfer)
  transfer_total = transfer_total + transfer
  call setKernelTime(13,userSubroutine,t3-t2,t2-t1,transfer_total,1)
end subroutine
END MODULE
